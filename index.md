---
layout: archive
author_profile: true
title: 
redirect_from: /about/
last_modified_at: "2025-10-28"
date: "2025-10-28"
---

<!-- weird tags? neural network whisperer / product minded AI / pulse on AI zeitgeist / love for X -->

<!-- name pronounciation example? [â–¶ï¸](https://upload.wikimedia.org/wikipedia/commons/c/c8/Example.ogg) -->

ðŸ‘‹ Hi, Iâ€™m Akash, an applied researcher/engineer with industry experience in speech, audio (at [Microsoft](https://www.microsoft.com/en-us/research/group/cognitive-services-research/speech/)), and most recently multi-modal document extraction, understanding and retrieval (at [Contextual AI](https://contextual.ai/)). I recently realized this completes the trio of audio, vision and language multimodality. :)

Iâ€™m currently on a brief sabbatical, exploring ideas & tinkering as I work out whatâ€™s next. Currently exploring real-time, on-device neural audio in the context of music and voice.

# Work 

## Contextual AI

Wrangled millions of pages to land the first $ millions in enterprise contracts :)

* 0â†’1: Built the core document understanding system (parsing, representation and ingestion) powering context retrieval platform over multimodal enterprise documents, also released as standalone API. Conducted applied research on document representation for agentic retrieval systems.
* Tech Lead / Manager: Mentored, managed, interviewed candidates, DRI with customers, marketing, PM.
* Links:
    * [Introducing the Document Parser for RAG](https://contextual.ai/blog/document-parser-for-rag/)
    * [Demo: llms.txt for Documents - Beyond Retrieval to Agentic Navigation](https://www.linkedin.com/feed/update/urn:li:activity:7346595035770929152?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_position_details%3BDHx4XhiTTqa5vQToJtWF3w%3D%3D)

## Microsoft

Fun fact: ~6M hours of monthly traffic equals 1 *year* of conversations transcribed per hour!

* Shipped and optimized state of art models transcribing millions of hours of monthly conversations on Azure and Microsoft Teams APIs.
* Research engineering: data pipeline, distributed training framework, profiling, optimizing for inference in ONNX/C++
* Applied research: Scalability focused architecture design, data & training recipes, error analysis, evaluation metrics
* Granted a patent and made a contribution to whisper.cpp (38k stars)
* Links:
    * [Batch transcription - Azure AI Speech service](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/batch-transcription)
    * [tinydiarize: speaker diarization prototype in whisper.cpp](https://x.com/ggerganov/status/1676271637572853771)
    * [US Patent US11563784B2: Caption assisted calling to maintain connection in challenging network conditions](https://patents.google.com/patent/US11563784B2/en)

Was one of the few non-PhD senior members on the team :)

# Misc 

- [2023] ðŸ¥ðŸ—£ï¸ Open-sourced [tinydiarize](https://github.com/akashmjn/tinyDiarize): an extension of OpenAI's Whisper ASR model for speaker diarization. It is runnable on Macbooks/iPhones via a contribution to [whisper.cpp](https://twitter.com/ggerganov/status/1676271637572853771) (38k stars).
- [2020] ðŸ‹ Co-founded OrcaHello, a system for 24/7 Southern Resident Killer Whale detection across Pacific Northwest hydrophones, which received a [$30,000 AI for Earth Innovation Grant](https://wildlabs.net/funding-opportunity/ai-earth-innovation-grant-extended) in 2020 and has been operating live for >4 years - [listen here](http://orcahello.ai4orcas.net/Dashboard).

<!-- Don't hesitate to reach out at [akashmjn.1] [at] [gmail] [dot] [--] with any thoughts, collaborations, or opportunites! -->
