---
layout: archive
author_profile: true
title: 
last_updated: "June 2021"
---

Hi! I currently wear a few hats as an Applied Scientist at Microsoft:

As an ML engineer, I've shipped world-class hybrid speech recognition models to 2 Azure APIs: [CTS](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/conversation-transcription) & [Speech-to-text](https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/), that have powered products such as [Word Transcribe](https://twitter.com/Gizmodo/status/1298865348733808641?s=20), [Twitter Spaces](https://twitter.com/jakhorner/status/1353878279841861635?s=20) & [PowerPoint Coach](https://news.microsoft.com/europe/2019/06/18/say-hello-to-presenter-coach-powerpoints-new-ai-powered-tool-which-will-help-you-nail-your-next-presentation/). Naturally this also meant fun times wrangling with our big-data & MLOps pipelines; a migration out of CNTK (legacy) involving lots of gnarly [ML debugging](http://josh-tobin.com/troubleshooting-deep-neural-networks.html); and contributing to a shiny new Pytorch hybrid ASR toolkit.

As a scientist, I closely track relevant research, adapting it as necessary (on occasion, trying to improve on it). After an initial investigation into accent robustness in &apos;19, i'm currently diving deep into self-supervised representation learning, which I expect will soon transform all speech & audio-related tasks.

Recently, I've also spent some time working across teams (multi-microphone processing, ASR, speaker-segmentation, diarization, LM, NLP) for an [ambitious incubation project](https://www.youtube.com/watch?v=ddb3ZgAp9TA) targeting conversations (*both in-person & remote*). Arguably the hardest ASR/NLP domain due to it's spontaneous structure + need for customization. Here it is paramount to *prioritize & measure the right things* - which is what I've been helping with via error analysis.

I entered into the code world via Python in 2015 ~6yrs ago (MATLAB doesn't really count, does it!). In a previous life, I majored in Chemical Engineering in my undergraduate - having seen hydrofracking & nicotine manufacture up close. As part of a minor in Control Systems, I was exposed to some signal processing, which has kind of come full circle with my long-time fascination with audio at the moment :)

<!-- I'm really excited about audio/signal processing applications of machine learning. Don't hesitate to reach out at [akashmjn] [at] [stanford] [dot] [edu] regarding collaborations, or opportunites!  -->
